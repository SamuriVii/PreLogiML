from typing import Optional, List, Tuple
from kafka import KafkaConsumer
import json
import time

import random
from sentence_transformers import SentenceTransformer
import numpy as np

# --- OpÃ³Åºnienie startu ---
print("Kontener startuje")
time.sleep(60)

# --- Importy poÅ‚Ä…czenia siÄ™ i funkcji Å‚Ä…czÄ…cych siÄ™ z PostGreSQL i innych---
from shared.db_utils import save_log, save_bus_cluster_record, save_bus_class_record
from shared.preprocessing_utils import enrich_data_with_environment, refactor_buses_data, rename_keys, replace_nulls, create_bus_summary_sentence
from shared.clusterization.clusterization import BusClusterPredictor
from shared.classification.classification import bus_binary_predictor, bus_multiclass_predictor, bus_regression_predictor, get_all_predictors_status 

bus_cluster_predictor = BusClusterPredictor()

# --- Ustawienia podstawowe ---
KAFKA_BROKER = "kafka-broker-1:9092"
KAFKA_TOPIC = "buses"
KAFKA_GROUP = "buses-subscriber"  

# --- Ustawienie Kafka Subscriber ---
consumer = KafkaConsumer(
    KAFKA_TOPIC,
    bootstrap_servers=KAFKA_BROKER,
    auto_offset_reset='earliest',
    enable_auto_commit=True,
    group_id=KAFKA_GROUP,
    value_deserializer=lambda x: json.loads(x.decode('utf-8'))
)

print(f"âœ… Subskrybent dziaÅ‚a na topicu '{KAFKA_TOPIC}'...")
bus_cluster_predictor.load_model()

print("\n--- Status zaÅ‚adowanych modeli klasyfikacji/regresji ---")
current_model_statuses = get_all_predictors_status()
for model_name, status_info in current_model_statuses.items():
    print(f"  Model: {model_name}, ZaÅ‚adowany: {status_info['loaded']}, ÅšcieÅ¼ka: {status_info['model_path']}")
    if not status_info['loaded']:
        print(f"    WiadomoÅ›Ä‡ statusu: {status_info['status_message']}")

# Model zostanie pobrany do lokalnego cache'u przy pierwszym uruchomieniu
print("ğŸ”„ Åadowanie modelu SentenceTransformer: all-MiniLM-L6-v2...")
try:
    embedding_model = SentenceTransformer('all-MiniLM-L6-v2')
    print("âœ… Model SentenceTransformer zaÅ‚adowany pomyÅ›lnie!")
except Exception as e:
    embedding_model = None
    print(f"âŒ BÅ‚Ä…d Å‚adowania modelu SentenceTransformer: {e}")
    print("   Upewnij siÄ™, Å¼e masz poÅ‚Ä…czenie z internetem (przy pierwszym uruchomieniu) i biblioteka jest zainstalowana.")

# --- Funkcja do generowania embeddingu (teraz uÅ¼ywa SentenceTransformer) ---
def generate_embedding(text: str) -> Optional[List[float]]:
    """
    Generuje embedding dla danego tekstu za pomocÄ… zaÅ‚adowanego modelu.
    """
    if embedding_model is None:
        print("âš ï¸ Model embeddingowy nie zaÅ‚adowany. Nie moÅ¼na wygenerowaÄ‡ embeddingu.")
        return None
    try:
        # Kodowanie tekstu i konwersja na listÄ™ Pythona
        embedding = embedding_model.encode(text).tolist()
        return embedding
    except Exception as e:
        print(f"âŒ BÅ‚Ä…d podczas generowania embeddingu dla tekstu '{text[:50]}...': {e}")
        return None

try:
    for message in consumer:
        data = message.value
        data = refactor_buses_data(data)

        print("ğŸ§  ğŸ§  Odebrano wiadomoÅ›Ä‡:")
        print(json.dumps(data, indent=2, ensure_ascii=False))

        # WywoÅ‚ujemy funkcjÄ™ wzbogadzajÄ…cÄ… dane buses o dane Å›rodowiskowe (environment)
        enriched = enrich_data_with_environment("subscriber_buses", data)
        enriched = rename_keys(enriched)
        enriched = replace_nulls(enriched)

        save_bus_cluster_record(enriched)

        print("ğŸ§  ğŸ§  ğŸ§  ğŸ§  Wzbogacone dane:")
        print(json.dumps(enriched, indent=2, ensure_ascii=False))

        cluster_id = bus_cluster_predictor.predict_cluster_from_dict(enriched)
        
        if cluster_id is not None:
            enriched['cluster_id'] = cluster_id
            enriched['cluster_prediction_success'] = True
            print(f"ğŸ¯ Przewidziano klaster: {cluster_id}")
        else:
            enriched['cluster_id'] = None
            enriched['cluster_prediction_success'] = False
            print("âš ï¸ Nie udaÅ‚o siÄ™ przewidzieÄ‡ klastra")

        save_bus_class_record(enriched)
        
        print("ğŸ§  ğŸ§  ğŸ§  ğŸ§  ğŸ§  ğŸ§  ğŸ§  ğŸ§  Wzbogacone dane (z klastrem):")
        print(json.dumps(enriched, indent=2, ensure_ascii=False, default=str))

        # --- Predykcje Klasyfikacji i Regresji ---

        # Predykcja binarna (is_late)
        if bus_binary_predictor.is_loaded:
            binary_pred_result = bus_binary_predictor.predict(enriched)
            # Sprawdzamy, czy wynik jest krotkÄ… o 3 elementach
            if isinstance(binary_pred_result, Tuple) and len(binary_pred_result) == 3:
                prediction_num, probabilities, prediction_label = binary_pred_result # PrawidÅ‚owe rozpakowanie
                enriched['is_late_prediction'] = prediction_num
                enriched['is_late_probabilities'] = probabilities
                enriched['is_late_prediction_success'] = True
                enriched['is_late_label'] = prediction_label # Zapisujemy etykietÄ™ tekstowÄ…
                print(f"ğŸ¯ Predykcja binarna (is_late): {prediction_num} ({enriched['is_late_label']}), PrawdopodobieÅ„stwa: {probabilities}")
            else:
                enriched['is_late_prediction'] = None
                enriched['is_late_probabilities'] = None
                enriched['is_late_prediction_success'] = False
                enriched['is_late_label'] = None
                print(f"âš ï¸ BÅ‚Ä…d: NieprawidÅ‚owy wynik predykcji binarnej dla autobusu: {binary_pred_result}")
        else:
            enriched['is_late_prediction'] = None
            enriched['is_late_probabilities'] = None
            enriched['is_late_prediction_success'] = False
            enriched['is_late_label'] = None
            print(f"âš ï¸ Model {bus_binary_predictor.model_name} nie zaÅ‚adowany, pomijam predykcjÄ™ binarnÄ….")

        # Predykcja wieloklasowa (delay_category)
        if bus_multiclass_predictor.is_loaded:
            multiclass_pred_result = bus_multiclass_predictor.predict(enriched)
            # Sprawdzamy, czy wynik jest krotkÄ… o 3 elementach
            if isinstance(multiclass_pred_result, Tuple) and len(multiclass_pred_result) == 3:
                prediction_num, probabilities, prediction_label = multiclass_pred_result # PrawidÅ‚owe rozpakowanie
                enriched['delay_category_prediction'] = prediction_num
                enriched['delay_category_probabilities'] = probabilities
                enriched['delay_category_prediction_success'] = True
                enriched['delay_category_label'] = prediction_label # Zapisujemy etykietÄ™ tekstowÄ…
                print(f"ğŸ¯ Predykcja wieloklasowa (delay_category): {prediction_num} ({enriched['delay_category_label']}), PrawdopodobieÅ„stwa: {probabilities}")
            else:
                enriched['delay_category_prediction'] = None
                enriched['delay_category_probabilities'] = None
                enriched['delay_category_prediction_success'] = False
                enriched['delay_category_label'] = None
                print(f"âš ï¸ BÅ‚Ä…d: NieprawidÅ‚owy wynik predykcji wieloklasowej dla autobusu: {multiclass_pred_result}")
        else:
            enriched['delay_category_prediction'] = None
            enriched['delay_category_probabilities'] = None
            enriched['delay_category_prediction_success'] = False
            enriched['delay_category_label'] = None
            print(f"âš ï¸ Model {bus_multiclass_predictor.model_name} nie zaÅ‚adowany, pomijam predykcjÄ™ wieloklasowÄ….")

        # Predykcja regresji (average_delay_seconds)
        if bus_regression_predictor.is_loaded:
            regression_prediction = bus_regression_predictor.predict(enriched)
            # Sprawdzamy, czy wynik jest liczbÄ… zmiennoprzecinkowÄ…
            if isinstance(regression_prediction, float):
                # Zapisujemy oryginalnÄ… predykcjÄ™ przed obciÄ™ciem, do celÃ³w logowania/debugowania
                enriched['average_delay_seconds_prediction_original'] = regression_prediction
                # ObciÄ™cie wartoÅ›ci do minimum 0
                clipped_prediction = max(0, regression_prediction) 
                
                enriched['average_delay_seconds_prediction'] = clipped_prediction
                enriched['average_delay_seconds_prediction_success'] = True
                print(f"ğŸ¯ Predykcja regresji (average_delay_seconds): {clipped_prediction:.2f} sekund (oryginalna: {regression_prediction:.2f})")
                if regression_prediction < 0:
                    print("âš ï¸ UWAGA: Przewidywane opÃ³Åºnienie byÅ‚o ujemne i zostaÅ‚o obciÄ™te do 0.")
            else:
                enriched['average_delay_seconds_prediction'] = None
                enriched['average_delay_seconds_prediction_success'] = False
                enriched['average_delay_seconds_prediction_original'] = None
                print(f"âš ï¸ BÅ‚Ä…d: NieprawidÅ‚owy wynik predykcji regresji dla autobusu: {regression_prediction}")
        else:
            enriched['average_delay_seconds_prediction'] = None
            enriched['average_delay_seconds_prediction_success'] = False
            enriched['average_delay_seconds_prediction_original'] = None
            print(f"âš ï¸ Model {bus_regression_predictor.model_name} nie zaÅ‚adowany, pomijam predykcjÄ™ regresji.")

        print("ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ Wzbogacone dane (z klastrem i predykcjami klasyfikacji/regresji):")
        print(json.dumps(enriched, indent=2, ensure_ascii=False, default=str))

        # --- Tworzenie zdania podsumowujÄ…cego (nowa czÄ™Å›Ä‡) ---
        summary_sentence = create_bus_summary_sentence(enriched) # WywoÅ‚anie zaimportowanej funkcji
        print(f"\nğŸ“ Wygenerowane zdanie podsumowujÄ…ce: {summary_sentence}")

        # --- NastÄ™pny krok: generowanie embeddingu (tylko print, bez faktycznego generowania na razie) ---
        print("\nâ¡ï¸ Gotowy do generowania embeddingu za pomocÄ… SentenceTransformers: all-MiniLM-L6-v2.")
        print("   (W tym miejscu wywoÅ‚aÅ‚byÅ› model embeddingowy dla zdania: '{summary_sentence}')")

        # --- Generowanie i zapis embeddingu ---
        embedding = generate_embedding(summary_sentence)
        if embedding is not None:
            print("\nâ¡ï¸ Wygenerowany Embedding:")
            print(embedding)
        else:
            save_log("subscriber_buses", "error", "Nie udaÅ‚o siÄ™ wygenerowaÄ‡ embeddingu dla autobusu.")







except KeyboardInterrupt:
    print("â›” Subskrybent zatrzymany rÄ™cznie (Ctrl+C).")
    save_log("subscriber_buses", "info", "Subskrybent zatrzymany rÄ™cznie.")
except Exception as e:
    print(f"âŒ BÅ‚Ä…d krytyczny subskrybenta: {str(e)}")
    save_log("subscriber_buses", "error", f"BÅ‚Ä…d subskrybenta: {str(e)}")
finally:
    consumer.close()
    print("ğŸ§¹ PoÅ‚Ä…czenie z Kafka zakoÅ„czone.")
