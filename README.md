# ğŸ¤– System AI dla Inteligentnego Miasta

Ten projekt to kompleksowe rozwiÄ…zanie wykorzystujÄ…ce sztucznÄ… inteligencjÄ™ do monitorowania miejskiej infrastruktury. System Å‚Ä…czy w sobie moÅ¼liwoÅ›ci duÅ¼ych modeli jÄ™zykowych (LLM), baz danych wektorowych, monitoringu przepÅ‚ywu danych oraz tradycyjnych modeli uczenia maszynowego, aby dostarczaÄ‡ inteligentne predykcje danych rowerowych (Mevo) oraz autobusowych (ZKM).

---

## â„¹ï¸ Podstawowe Informacje

Ten projekt integruje szereg technologii, ktÃ³re wspÃ³Å‚dziaÅ‚ajÄ… w ekosystemie Docker Compose. PoniÅ¼ej znajdziesz kluczowe adresy, pod ktÃ³rymi moÅ¼esz monitorowaÄ‡ i zarzÄ…dzaÄ‡ poszczegÃ³lnymi komponentami systemu po jego uruchomieniu:

* **PGAdmin4:** [http://localhost:8080](http://localhost:8080) â€“ Interfejs graficzny do zarzÄ…dzania bazami danych PostgreSQL. Tutaj znajdziesz wyniki predykcji i inne dane operacyjne.
* **ChromaDB:** [http://chroma:8000](http://chroma:8000) â€“ Twoja baza danych wektorowych, wykorzystywana przez AnythingLLM do przechowywania i wyszukiwania osadzeÅ„.
* **AnythingLLM:** [http://localhost:3001](http://localhost:3001) â€“ Platforma do budowania aplikacji LLM z bazami wiedzy. SÅ‚uÅ¼y do interakcji z modelem jÄ™zykowym w kontekÅ›cie danych z systemu.
* **Node-RED:** [http://localhost:1880](http://localhost:1880) â€“ Åšrodowisko do wizualnego programowania przepÅ‚ywÃ³w danych. Tutaj moÅ¼esz monitorowaÄ‡ czÄ™stotliwoÅ›Ä‡ uruchamiania i status poszczegÃ³lnych procesÃ³w w systemie.

---

## ğŸš€ Instrukcja Uruchamiania Systemu

Aby poprawnie uruchomiÄ‡ caÅ‚y ekosystem, wykonaj poniÅ¼sze kroki:

1.  **Sklonuj Repozytorium:**
    ```bash
    git clone <URL_TWOJEGO_REPOZYTORIUM>
    cd <NAZWA_TWOJEGO_REPOZYTORIUM>
    ```

2.  **Uruchom Docker Compose:**
    Upewnij siÄ™, Å¼e masz zainstalowanego Dockera i Docker Compose (zalecane Å›rodowisko to WSL z Dockerem na systemach Windows). NastÄ™pnie przejdÅº do katalogu gÅ‚Ã³wnego projektu i uruchom wszystkie usÅ‚ugi:
    ```bash
    docker compose up -d
    ```
    Poczekaj chwilÄ™, aÅ¼ wszystkie usÅ‚ugi zostanÄ… pobrane i uruchomione. Proces ten moÅ¼e potrwaÄ‡ kilka minut przy pierwszym uruchomieniu.

3.  **Weryfikacja DziaÅ‚ania:**
    Po uruchomieniu kontenerÃ³w moÅ¼esz sprawdziÄ‡ ich status:
    ```bash
    docker compose ps
    ```
    Wszystkie usÅ‚ugi powinny byÄ‡ w stanie `running`.

---

## ğŸ”‘ Konfiguracja AnythingLLM (Po Uruchomieniu)

Po uruchomieniu systemu, naleÅ¼y skonfigurowaÄ‡ AnythingLLM, aby poÅ‚Ä…czyÄ‡ go z wybranym modelem jÄ™zykowym i bazÄ… danych wektorowych.

1.  **OtwÃ³rz AnythingLLM:** PrzejdÅº do [http://localhost:3001](http://localhost:3001) w swojej przeglÄ…darce.
2.  **Ustawienia Dostawcy LLM:**
    * PrzejdÅº do **UstawieÅ„** (Settings) w interfejsie AnythingLLM.
    * Wybierz sekcjÄ™ **Providers**.
    * Jako dostawcÄ™ modelu LLM wybierz **OpenAI** (lub innego preferowanego dostawcÄ™).
    * **Generowanie Klucza API OpenAI:** JeÅ›li uÅ¼ywasz OpenAI, wygeneruj swÃ³j klucz API na platformie OpenAI: [https://platform.openai.com/settings/organization/api-keys](https://platform.openai.com/settings/organization/api-keys).
    * WprowadÅº swÃ³j wygenerowany **klucz API** (np. `sk-proj-LXKa8BtDxP36K5oXXX`) w odpowiednie pole w AnythingLLM.
    * Wybierz preferowany model LLM (np. `gpt-4o`, `gpt-3.5-turbo`).
3.  **Ustawienia Bazy Wektorowej (Vector Database):**
    * W sekcji **Vector Database** wybierz **ChromaDB**.
    * W polu adresu wprowadÅº: `http://chroma:8000`.
    * Zapisz zmiany.

Gotowe! AnythingLLM jest teraz poÅ‚Ä…czone z Twoim modelem LLM i bazÄ… danych wektorowych.

---

## ğŸ“ˆ Monitorowanie i Wyniki

* **Node-RED:** Na stronie [http://localhost:1880](http://localhost:1880) moÅ¼esz obserwowaÄ‡ przepÅ‚ywy danych i czÄ™stotliwoÅ›Ä‡ uruchamiania poszczegÃ³lnych procesÃ³w. W przyszÅ‚oÅ›ci planujemy dodaÄ‡ szczegÃ³Å‚owe opisy odpowiedzialnoÅ›ci kaÅ¼dego z procesÃ³w, a takÅ¼e **zrzuty ekranu** (moÅ¼esz wstawiaÄ‡ je uÅ¼ywajÄ…c skÅ‚adni `![Opis zdjÄ™cia](Å›cieÅ¼ka/do/zdjÄ™cia.png)`) dla lepszej wizualizacji.
* **PGAdmin4:** W PGAdmin4, po poÅ‚Ä…czeniu siÄ™ z bazÄ… danych, moÅ¼esz przeglÄ…daÄ‡ tabelÄ™ `llm_test_results`, ktÃ³ra przechowuje wyniki predykcji i inne istotne dane generowane przez system.

---

## ğŸ› ï¸ Dalszy RozwÃ³j

Obecnie README zawiera podstawowe informacje i instrukcje. W kolejnych etapach rozwoju projektu planujemy rozbudowaÄ‡ dokumentacjÄ™ o:

* SzczegÃ³Å‚owÄ… strukturÄ™ bazy danych (schematy tabel, opisy kolumn).
* DokumentacjÄ™ dotyczÄ…cÄ… funkcji i klas w kodzie.
* PrzykÅ‚adowe zastosowania i scenariusze uÅ¼ycia systemu.
* WiÄ™cej zrzutÃ³w ekranu i wizualizacji dziaÅ‚ania.
